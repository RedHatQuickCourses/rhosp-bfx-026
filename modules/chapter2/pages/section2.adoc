= Guided solution (page 2)

. Capture ARP request packets using **tcpdump** on **compute** node.
+
[source, bash]
----
tcpdump -i eth2 arp -c1 -w arp-request.pcap
----
+
.Sample output
----
[root@compute01 ~]# tcpdump -i eth2 arp -c1 -w arp-request.pcap
dropped privs to tcpdump
tcpdump: listening on eth2, link-type EN10MB (Ethernet), capture size 262144 bytes
1 packet captured
1 packet received by filter
0 packets dropped by kernel
----
+
Before running the above command, ensure to **ping the floating IP** from another terminal **from workstation vm** to generate the necessary packets.

. Check if the captured packets are ARP requests for the floating IP.
+
[source, bash]
----
tcpdump -r arp-request.pcap
----
+
.Sample output
----
[root@compute01 ~]# tcpdump -r arp-request.pcap
reading from file arp-request.pcap, link-type EN10MB (Ethernet), snapshot length 262144
dropped privs to tcpdump
06:12:38.696143 ARP, Request who-has 192.168.51.98 tell _gateway, length 28
[root@compute01 ~]# 
----

. Run below command on the **compute** node to identify the OpenFlow protocol number for network interface eth2.
+
[source, bash]
----
ovs-ofctl show br-ex
----
+
.Sample output
----
[root@compute01 ~]# ovs-ofctl show br-ex
OFPT_FEATURES_REPLY (xid=0x2): dpid:000052540002331f
n_tables:254, n_buffers:0
capabilities: FLOW_STATS TABLE_STATS PORT_STATS QUEUE_STATS ARP_MATCH_IP
actions: output enqueue set_vlan_vid set_vlan_pcp strip_vlan mod_dl_src mod_dl_dst mod_nw_src mod_nw_dst mod_nw_tos mod_tp_src mod_tp_dst
 1(eth2): addr:52:54:00:02:33:1f
     config:     0
     state:      0
     speed: 0 Mbps now, 0 Mbps max
 LOCAL(br-ex): addr:52:54:00:02:33:1f
     config:     0
     state:      0
     speed: 0 Mbps now, 0 Mbps max
OFPT_GET_CONFIG_REPLY (xid=0x4): frags=normal miss_send_len=0
[root@compute01 ~]# 
----
+
[NOTE]
====
eth2 is associated with port number 1
====

. On the **compute** node, perform the OpenFlow protocol trace on **br-ex** with in_port set to 1.
+
[source, bash]
----
ovs-appctl ofproto/trace br-ex in_port=1 $(ovs-pcap arp-request.pcap)
----
+
- **ovs-pcap** command is provided by **openvswitch-test** package.
- openvswitch-test package is available form the **fast-datapath-for-rhel-9-x86_64-rpms** channel.
- Subscribe the compute node and enable fast-datapath-for-rhel-9-x86_64-rpms channel.
- Install **openvswitch3.3-test-3.3.0-49.el9fdp.noarch** package.
+
[source, bash]
----
subscription-manager register
subscription-manager repos --enable=fast-datapath-for-rhel-9-x86_64-rpms
dnf install openvswitch3.3-test-3.3.0-49.el9fdp.noarch
----
+
.Sample output
----
[root@compute01 ~]# ovs-appctl ofproto/trace br-ex in_port=1 $(ovs-pcap arp-request.pcap)
-bash: ovs-pcap: command not found
Flow: in_port=1,vlan_tci=0x0000,dl_src=00:00:00:00:00:00,dl_dst=00:00:00:00:00:00,dl_type=0x0000

bridge("br-ex")
---------------
 0. priority 0
    NORMAL
     -> no learned MAC for destination, flooding

Final flow: unchanged
Megaflow: recirc_id=0,eth,in_port=1,dl_src=00:00:00:00:00:00,dl_dst=00:00:00:00:00:00,dl_type=0x0000
Datapath actions: 3
[root@compute01 ~]# 
----

. The trace shows that the ARP request is flooding, and "Datapath actions: 3" indicates that it was delivered to br-ex (see output of below command).
+
----
[root@compute01 ~]# ovs-dpctl show
system@ovs-system:
  lookups: hit:5562620 missed:182693 lost:0
  flows: 27
  masks: hit:11191975 total:5 hit/pkt:1.95
  cache: hit:2462172 hit-rate:42.86%
  caches:
    masks-cache: size:256
  port 0: ovs-system (internal)
  port 1: genev_sys_6081 (geneve: packet_type=ptap)
  port 2: br-int (internal)
  port 3: br-ex (internal)
  port 4: br-osp (internal)
  port 5: eth2
  port 6: eth3
  port 7: vlan20 (internal)
  port 8: vlan21 (internal)
  port 9: vlan22 (internal)
  port 10: tapd2db5833-99
  port 11: tap96cd71b0-20
[root@compute01 ~]# 
----
+
[NOTE]
====
"Data path 3" means the traffic was delivered to br-ex, which is a port 3 on the br-ex bridge.
====

. Run tcpdump on br-exon the **compute** node.
+
[source, bash]
----
tcpdump -envvi br-ex arp
----
+
.Sample output
----
[root@compute01 ~]# tcpdump -envvi br-ex arp
dropped privs to tcpdump
tcpdump: listening on br-ex, link-type EN10MB (Ethernet), snapshot length 262144 bytes
08:12:19.474463 52:54:00:02:33:fe > Broadcast, ethertype ARP (0x0806), length 42: Ethernet (len 6), IPv4 (len 4), Request who-has 192.168.51.98 tell 192.168.51.254, length 28
08:12:20.521301 52:54:00:02:33:fe > Broadcast, ethertype ARP (0x0806), length 42: Ethernet (len 6), IPv4 (len 4), Request who-has 192.168.51.98 tell 192.168.51.254, length 28
08:12:21.545346 52:54:00:02:33:fe > Broadcast, ethertype ARP (0x0806), length 42: Ethernet (len 6), IPv4 (len 4), Request who-has 192.168.51.98 tell 192.168.51.254, length 28
----
+
- The output shows ARP requests, indicating that the traffic is indeed being received by the br-ex port.

- However, the issue lies in why this traffic is not making its way to br-int, which is crucial for proper network routing.

- There is a floating IP configured on a particular compute node.

- OVN (Open Virtual Network) is aware of this configuration.

- OVN creates a patch port between the provider network and br-int. * Importantly, each provider network has its own patch port connecting br-ex and br-int.

. Review at the ovs-vsctl show output captured earlier, br-ex has only one port - eth2, which is the NIC (Network Interface Card) of the compute node.
+
----
[root@compute01 ~]# ovs-vsctl show
. . .
    Bridge br-ex
        fail_mode: standalone
        Port br-ex
            Interface br-ex
                type: internal
        Port eth2
            Interface eth2
. . .
----
+
The key issue here is the absence of a patch port between br-int and br-ex. This missing link prevents traffic from flowing properly between the internal network (br-int) and the external network (br-ex).

. Now let us examine your OVN bridge mappings. Run the below command on the **compute** node.
+
[source, bash]
----
ovs-vsctl list open .
----
+
.Sample output
----
[root@compute01 ~]# ovs-vsctl list open .
_uuid               : f40f8bed-c407-4a8e-82c6-5e2b609bd143
bridges             : [0964364a-dc77-4dcc-8e8d-5889c53e6749, 39832bfb-915c-41be-9ebd-22bf04fb17dd, b02d474e-5d5c-41e2-ad77-976d7b4c44d2]
cur_cfg             : 39
datapath_types      : [netdev, system]
datapaths           : {system=5663d999-85b5-475f-b893-6916270b4b68}
db_version          : "8.5.0"
dpdk_initialized    : false
dpdk_version        : "DPDK 23.11.2"
external_ids        : {hostname=compute01.srv.example.com, ovn-bridge=br-int, ovn-chassis-mac-mappings="datacentre:0e:0a:38:8e:8e:08", ovn-encap-ip="172.19.0.110", ovn-encap-tos="0", ovn-encap-type=geneve, ovn-match-northd-version=False, ovn-monitor-all=True, ovn-ofctrl-wait-before-clear="8000", ovn-remote="ssl:ovsdbserver-sb.openstack.svc:6642", ovn-remote-probe-interval="60000", rundir="/var/run/openvswitch", system-id="6b475747-b459-4488-b670-91252b56d663"}
iface_types         : [bareudp, erspan, geneve, gre, gtpu, internal, ip6erspan, ip6gre, lisp, patch, srv6, stt, system, tap, vxlan]
manager_options     : [241be795-53a8-4fef-be2a-667d77558060]
next_cfg            : 39
other_config        : {ovn-chassis-idx-6b475747-b459-4488-b670-91252b56d663="", vlan-limit="0"}
ovs_version         : "3.3.4-62.el9fdp"
ssl                 : []
statistics          : {}
system_type         : rhel
system_version      : "9.4"
[root@compute01 ~]# 
----
+
[NOTE]
====
Bridge mappings are important for determining which provider network corresponds to a specific bridge.
====

. This output shows the OVN setup, including bridges, data paths, and various configurations. Bridge mapping is stored in external_ids.
+
----
external_ids        : {hostname=compute01.srv.example.com, ovn-bridge=br-int, ovn-chassis-mac-mappings="datacentre:0e:0a:38:8e:8e:08", ovn-encap-ip="172.19.0.110", ovn-encap-tos="0", ovn-encap-type=geneve, ovn-match-northd-version=False, ovn-monitor-all=True, ovn-ofctrl-wait-before-clear="8000", ovn-remote="ssl:ovsdbserver-sb.openstack.svc:6642", ovn-remote-probe-interval="60000", rundir="/var/run/openvswitch", system-id="6b475747-b459-4488-b670-91252b56d663"}
iface_types         : [bareudp, erspan, geneve, gre, gtpu, internal, ip6erspan, ip6gre, lisp, patch, srv6, stt, system, tap, vxlan]
----
+
Notably, it lacks information about bridge mappings. Bridge mappings play an important role in associating a NIC with a provider network (commonly referred to as a datacenter network). In this case OVN does not know which provider network is the datacenter because it needs to map between the NIC and the provider network. To create this connection, we need to inform OVN about the relationship between the NIC and the provider network, typically named 'datacenter'.

. Explore public network details from the **workstation** vm.
+
[source, bash]
----
oc exec -n openstack openstackclient -- openstack network show public
----
+
.Sample output
----
[student@workstation ~]$ oc exec -n openstack openstackclient -- openstack network show public
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | UP                                   |
| availability_zone_hints   |                                      |
| availability_zones        |                                      |
| created_at                | 2025-05-04T21:29:27Z                 |
| description               |                                      |
| dns_domain                |                                      |
| id                        | 5526bfcf-a164-4a91-ad99-90bb5c41f500 |
| ipv4_address_scope        | None                                 |
| ipv6_address_scope        | None                                 |
| is_default                | False                                |
| is_vlan_transparent       | None                                 |
| l2_adjacency              | True                                 |
| mtu                       | 1500                                 |
| name                      | public                               |
| port_security_enabled     | True                                 |
| project_id                | d388b58059514443a8dced8c2ed691f6     |
| provider:network_type     | flat                                 |
| provider:physical_network | datacentre                           |
| provider:segmentation_id  | None                                 |
| qos_policy_id             | None                                 |
| revision_number           | 2                                    |
| router:external           | External                             |
| segments                  | None                                 |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   | b5a9f748-df82-436a-b8e3-14912e258b5d |
| tags                      |                                      |
| tenant_id                 | d388b58059514443a8dced8c2ed691f6     |
| updated_at                | 2025-05-04T21:29:35Z                 |
+---------------------------+--------------------------------------+
[student@workstation ~]$ 
----
+
In this output, find information about the "public" network, including its physical network, which is labeled as **datacentre**.
+
----
| provider:physical_network | datacentre
----
+
This is essentially a placeholder name that we define in configuration files. We need to specify which NIC on the compute nodes corresponds to this "datacenter" network.
+
[NOTE]
====
The issue at hand is that OVN does not inherently know that the **br-ex** bridge represents the **datacenter provider network**.
====
+
To establish this link, we must explicitly configure OVN bridge mappings. This configuration ensures that OVN associates br-ex with the datacenter network.

. Configure the OVN bridge mapping settings using the ovs-vsctl set command on the **compute** node.
+
[source, bash]
----
ovs-vsctl set open . external_ids:ovn-bridge-mappings=datacentre:br-ex
----
+
.Sample output
----
[root@compute01 ~]# ovs-vsctl set open . external_ids:ovn-bridge-mappings=datacentre:br-ex
----

. Re-run the ovs-vsctl show command on the **compute** node to verify that a patch port has been created between br-int and br-ex.
+
[source, bash]
----
ovs-vsctl show
----
+
.Sample output
----
[root@compute01 ~]# ovs-vsctl show
. . .
    Bridge br-ex
        fail_mode: standalone
        Port br-ex
            Interface br-ex
                type: internal
        Port eth2
            Interface 
            
        Port patch-provnet-392f50ef-731c-4984-916d-9ce45906ace1-to-br-int
            Interface patch-provnet-392f50ef-731c-4984-916d-9ce45906ace1-to-br-int
                type: patch
                options: {peer=patch-br-int-to-provnet-392f50ef-731c-4984-916d-9ce45906ace1}
    Bridge br-int
        fail_mode: secure
        datapath_type: system
. . .
        Port patch-br-int-to-provnet-392f50ef-731c-4984-916d-9ce45906ace1
            Interface patch-br-int-to-provnet-392f50ef-731c-4984-916d-9ce45906ace1
                type: patch
                options: {peer=patch-provnet-392f50ef-731c-4984-916d-9ce45906ace1-to-br-int}
. . . 
----
+
This connection is crucial for proper network communication. By addressing this missing link, we can ensure that traffic flows smoothly between the internal and external networks, thus resolving the connectivity issue we encountered.

